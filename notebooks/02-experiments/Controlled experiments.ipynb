{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controlled experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "require(readxl)\n",
    "require(dplyr)\n",
    "require(pwr)\n",
    "require(effsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "We are going to replicate analysis for two hypothesis formulated in the paper:\n",
    "\n",
    "```\n",
    "@article{salman2019controlled,\n",
    "  title={A controlled experiment on time pressure and confirmation bias in functional software testing},\n",
    "  author={Salman, Iflaah and Turhan, Burak and Vegas, Sira},\n",
    "  journal={Empirical Software Engineering},\n",
    "  volume={24},\n",
    "  number={4},\n",
    "  pages={1727--1761},\n",
    "  year={2019},\n",
    "  publisher={Springer}\n",
    "}\n",
    "```\n",
    "\n",
    "The aim of this research was as follows: Analyse the ***functional test cases*** For the purpose of ***examining the effects of time pressure With respect to confirmation bias*** From the point of view of researchers In the context of an experiment run with graduate students (as proxies for novice professionals) in an academic setting.\n",
    "\n",
    "Before we continue, let's introduce some terms:\n",
    "\n",
    "***Consistent test case (c):*** A consistent test case tests strictly according to what has been specified in the requirements, i.e. consistency with the specified behaviour. In the context of testing this refers to: 1) the defined program behaviour on a certain input; and 2) the defined behaviour for a specified invalid input. Example: If the specifications state, “… the phone number field does not accept alphabetic characters...”, the test case designed to validate that phone number field does not accept alphabetic characters is considered a consistent test case.\n",
    "\n",
    "***Inconsistent test case (ic):*** An inconsistent test case tests the scenario or the data input that is not explicitly specified in the requirements. We also consider such test cases that present outside-of-the-box thinking at the tester’s end inconsistent. Example: If the specifications only state, “… the phone number field accepts digits...”, and the application’s behaviour for the other types of input for that field is not specified, then the following test case is considered inconsistent: the phone number field accepts only the + sign from the set of special characters (e.g. to set an international call prefix).\n",
    "\n",
    "***Proxy Measure of Confirmation Bias***\n",
    "\n",
    "We mark the functional test cases designed by the participants as either consistent (c) or inconsistent (ic). To detect the bias of participants through a proxy measure, we derive a scalar parameter based on (c) and (ic) test cases designed by the participants and the total count of (all possible) consistent (C) and inconsistent (IC) test cases for the given specification:\n",
    "\n",
    "𝑧=𝑐/𝐶−𝑖𝑐/𝐼𝐶\n",
    "\n",
    "* if z >0 ; participant has designed relatively more consistent test cases\n",
    "\n",
    "* if z <0 ; participant has designed relatively more inconsistent test cases\n",
    "\n",
    "* if z = 0 ; participant has designed a relatively equal number of consistent and inconsistent test cases.\n",
    "\n",
    "***Hypothesis Formulation***\n",
    "\n",
    "*H1 states that: Testers design more consistent test cases than inconsistent test cases.*\n",
    "\n",
    "𝐻1𝐴:𝜇(𝑐)>𝜇(𝑖𝑐)\n",
    "\n",
    "𝐻10:𝜇(𝑐)≤𝜇(𝑖𝑐)\n",
    "\n",
    "*H3: Testers under time pressure manifest relatively more confirmation bias than testers under no time pressure.*\n",
    "\n",
    "𝐻3𝐴:𝜇(𝑧𝑇𝑃)>𝜇(𝑧𝑁𝑇𝑃)\n",
    "\n",
    "𝐻30:𝜇(𝑧𝑇𝑃)≤𝜇(𝑧𝑁𝑇𝑃)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_data <- read_excel(\"experiment1.xlsx\", sheet=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(exp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TP = Time Presure\n",
    "NTP = No Time Pressure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(exp_data %>% select(C_TP, IC_TP, Z_TP, C_NTP, IC_NTP, Z_NTP) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H1 states that: Testers design more consistent test cases than inconsistent test cases.\n",
    "\n",
    "𝐻1𝐴:𝜇(𝑐)>𝜇(𝑖𝑐)\n",
    "\n",
    "𝐻10:𝜇(𝑐)≤𝜇(𝑖𝑐)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to combine two datasets because the question is in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_data <- data.frame(rbind(as.matrix(exp_data %>% select(C_TP, IC_TP)), \n",
    "                     as.matrix(exp_data %>% select(C_NTP, IC_NTP))))\n",
    "colnames(pooled_data) <- c(\"C\", \"IC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(pooled_data)\n",
    "head(pooled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate descriptive statistics and visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(pooled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=5, repr.plot.height=3)\n",
    "old_par <- par(mfrow=c(1,1), mar=c(3, 10, 2, 0), cex=0.7, omi=c(0,0,0,0), mgp=c(2, 1, 0))\n",
    "boxplot(pooled_data, \n",
    "     main=\"C vs IC\", \n",
    "     xlab=\"Test cases\", horizontal=TRUE)\n",
    "par(old_par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would have to decide what to do with the potential oultiers. The authors decided to no remove them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check normality assumption for both variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=5.5, repr.plot.height=3)\n",
    "old_par <- par(mfrow=c(1,2), mar=c(3, 3, 2, 0), cex=0.7, omi=c(0,0,0,0), mgp=c(2, 1, 0))\n",
    "\n",
    "qqnorm(pooled_data$C, main=\"Normal Q-Q for C\")\n",
    "qqline(pooled_data$C)\n",
    "\n",
    "qqnorm(pooled_data$IC, main=\"Normal Q-Q for IC\")\n",
    "qqline(pooled_data$IC)\n",
    "\n",
    "par(old_par)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro.test(pooled_data$C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro.test(pooled_data$IC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: there is strong evidence against normality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's better to use a non-parametric test. Going back to H1 our null hypothesis would be that there are not differences in median number of test cases for C and CI, while an alternative hypothesis would state that the median number of test cases is greater for C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilcox.test(pooled_data$C, pooled_data$IC, alternative=\"greater\", paired = TRUE )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the size of sample you can use procedure for t test and divide the value by A.R.E which is in this case equal 0.955"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd <- as.numeric(cohen.d(pooled_data$C, \n",
    "                         pooled_data$IC, na.rm=T)$estimate)\n",
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwr.t.test( n=dim(pooled_data)[1] , sig.level=0.05 , \n",
    "           power=NULL , d=cd , alternative='greater' ,\n",
    "           type='paired')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: **Tester are more likely to produce consistent tests**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H3: Testers under time pressure manifest relatively more confirmation bias than testers under no time pressure.\n",
    "\n",
    "𝐻3𝐴:𝜇(𝑧𝑇𝑃)>𝜇(𝑧𝑁𝑇𝑃)\n",
    "\n",
    "𝐻30:𝜇(𝑧𝑇𝑃)≤𝜇(𝑧𝑁𝑇𝑃)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_data <- exp_data %>% select(Z_TP, Z_NTP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate some descriptive statistics and visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(z_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=5, repr.plot.height=3)\n",
    "old_par <- par(mfrow=c(1,1), mar=c(3, 10, 2, 0), cex=0.7, omi=c(0,0,0,0), mgp=c(2, 1, 0))\n",
    "boxplot(z_data, \n",
    "     main=\"TP vs NTP\", \n",
    "     xlab=\"Z\", horizontal=TRUE,\n",
    "     names=c(\"TP\", \"NTP\"))\n",
    "par(old_par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would have to decide what to do with the potential oultiers. The authors decided to no remove them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check normality assumption for both variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=5.5, repr.plot.height=3)\n",
    "old_par <- par(mfrow=c(1,2), mar=c(3, 3, 2, 0), cex=0.7, omi=c(0,0,0,0), mgp=c(2, 1, 0))\n",
    "\n",
    "qqnorm(z_data$Z_TP, main=\"Normal Q-Q for TP\")\n",
    "qqline(z_data$Z_TP)\n",
    "\n",
    "qqnorm(z_data$Z_NTP, main=\"Normal Q-Q for NTP\")\n",
    "qqline(z_data$Z_NTP)\n",
    "\n",
    "par(old_par)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro.test(z_data$Z_TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro.test(z_data$Z_NTP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: there are no strong evidences against normality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the normality assumption seem valid, we can perform a paramteric test. By looking at H3 we could define two hypotheses: the null hypotheses will state that the mean z is the same for the TP and NTP groups while the alternative hypothesis will state that mean z is greater for the TP group (time pressure increases the Confirmation Bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.test(z_data$Z_TP, z_data$Z_NTP, alternative=\"greater\", paired = FALSE )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the size of sample you can use procedure for t test and divide the value by A.R.E which is in this case equal 0.955"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd <- as.numeric(cohen.d(z_data$Z_TP, \n",
    "                         z_data$Z_NTP, na.rm=T)$estimate)\n",
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwr.t.test( n=dim(z_data)[1] , sig.level=0.05 , \n",
    "           power=NULL , d=cd , alternative='greater' ,\n",
    "           type='two.sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: ***It is unlikely that time pressure affects confirmation bias***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Your taks will be to replicate one of the analyses described in the paper:\n",
    "\n",
    "```\n",
    "@article{mackowiak2018some,\n",
    "  title={On some end-user programming constructs and their understandability},\n",
    "  author={Ma{\\'c}kowiak, Micha{\\l} and Nawrocki, Jerzy and Ochodek, Miros{\\l}aw},\n",
    "  journal={Journal of Systems and Software},\n",
    "  volume={142},\n",
    "  pages={206--222},\n",
    "  year={2018},\n",
    "  publisher={Elsevier}\n",
    "}\n",
    "```\n",
    "\n",
    "The experiments in the paper evaluate some constructs that could be useful from the perspective of end-user programmers (end-user programming as a research area tackles with the problem of how to help domain experts that are not professional programmers write code to support their work).\n",
    "\n",
    "This particular experiment we will focus on investigated whether programs written using the single assignment paradigm can help in understanding programs. \n",
    "\n",
    "The understandability of a set of programming constructs, when evaluated by a group of people, can be described with the following performance indicators (we call them the FACT indicators of understandability):\n",
    "* F — first attempt failure ratio: the percentage of people (partic- ipants) who fail at the first attempt to predict the results of a computation defined by means of a given set of programming constructs;\n",
    "* A — attempt number: the average number of attempts needed to predict the correct results of computations defined by code containing the analysed programming constructs (if A = 1 then F = 0—all participants from the group predict the correct re- sults at the first attempt);\n",
    "* C — cancellation ratio: the percentage of participants who are unable to complete a given assignment (i.e. correctly predict the result, regardless of the number of attempts) in a given amount of time;\n",
    "* T — prediction time: the average time used by participants to predict the results of a computation defined by code composed of the analysed programming constructs.\n",
    "\n",
    "**The task of the participants was to predict the output generated by a given function written in two different ways: control group = standard way, experimental group = using a single assignment paradigm.**\n",
    "\n",
    "**We will limit our analysis here to the prediction time - T.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "Load data from the experiment2.xls file into and display the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate data frames for each group\n",
    "\n",
    "As you can see, the data frame contains data for both controll and experimental groups.\n",
    "\n",
    "Create two separate data frames by filtering the main one: \n",
    "* experiment - should contain observations with the Treatment \"Star\"\n",
    "* control - should contain observations with the Treatment \"Standard\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many participants were in both groups?\n",
    "\n",
    "Find out how many participants were in each of the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T - Prediction Time\n",
    "\n",
    "We will replicate the analysis for the prediction time. The null hypothesis is that there is no difference in prediction time (T) between the groups. The alternative hypothesis will state that \"average\" time for the experimental group is lower than for the control group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since not all the participants completed the task, we have to filter the samples:\n",
    "* **experiment** - reject all non-completed tasks for the experimental group (you should preserve only the rows with IsDone==\"True\" and IsCorrect==\"True\")\n",
    "* **control** - since the alternative hypothesis indicates the programs using the single assignment paradigm as superior, it is acceptable to favor the control group. Therefore, it was decided to accept all incompleted solutions with the assumption that the participants would finish in time T+1. Create a new column **TimeCorrected** in the control group data frame that will equal to: ```Time if IsDone==\"True\" and IsCorrect==\"True\" otherwise Time+1```. **Hint:** *if you want to use the mutate function from the dplyr package, you can use the function ifelse(condition, exp1, exp2)*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate descriptive statistics for the Prediction Time - the columns Time and TimeCorrected in the data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a boxplot comparing the distributions of T in both groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check normality assumption for both variables - check the QQ plots and conduct Shapiro-Wilk tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** What is your conclusion about the normality assumption? What kind of test will you use to investigate the hypotheses?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the statistical test of you choice to investigate the hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Conclusion:** What is you final conclusion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
